---
title: "baroth_OriginalHomeworkCode_05"
author: "Brooke Rothamer"
date: "`r Sys.Date()`"
output: 
  prettydoc::html_pretty:
    theme: cayman
    toc: yes
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Homework 5: Bootstrapping Standard Errors and CIs for Linear Models.

When we initially discussed the central limit theorem and confidence intervals, we showed how we could use bootstrapping to estimate standard errors and confidence intervals around certain parameter values, like the mean. Using bootstrapping, we could also do the same for estimating standard errors and CIs around regression parameters, such as β coefficients.

## Linear Regression

Using the “KamilarAndCooperData.csv” dataset, run a linear regression looking at log(HomeRange_km2) in relation to log(Body_mass_female_mean) and report your β coeffiecients (slope and intercept).

Load in data.
```{r data load in}
data <- as.data.frame(read.csv("https://raw.githubusercontent.com/fuzzyatelin/fuzzyatelin.github.io/master/AN588_Fall23/KamilarAndCooperData.csv"))
```

Run linear regression model.
```{r lm}
model <- lm(log(data$HomeRange_km2)~log(data$Body_mass_female_mean))
summary(model)

model_summary <- summary(model) # pulling out the coefficients this way to facilitate pulling out the standard error later
model_summary$coefficients[,1]
```
* β0 = -9.44123
* β1 = 1.03643

## Bootstrapping

Then, use bootstrapping to sample from your data 1000 times with replacement, each time fitting the same model and calculating the same coefficients. This generates a sampling distribution for each β coefficient.

Bootstrapping code adapted from [Medium's Bootstrap regression in R](https://towardsdatascience.com/bootstrap-regression-in-r-98bfe4ff5007).
```{r}
set.seed(42) #setting a seed will give the same sample every time the code is run

sample_coef_beta0 <- NULL # dummy variable to hold 1000 simulated intercepts
sample_coef_beta1 <- NULL # dummy variable to hold 1000 simulated slopes

for (i in 1:1000) { # for i 1 through 1000,
  sample_data = data[sample(1:nrow(data), nrow(data), replace = TRUE), ] #sample data of the same number of rows and columns is drawn from data
  
  bootstrap_model <- lm(log(sample_data$HomeRange_km2)~log(sample_data$Body_mass_female_mean)) #Run the regression on the sample_data
  
  
  sample_coef_beta0 <- c(sample_coef_beta0, bootstrap_model$coefficients[1]) #pull the intercept from each model and saves them in a vector
  
  sample_coef_beta1 <- c(sample_coef_beta1, bootstrap_model$coefficients[2]) #pull the slope from each model and saves them in a vector
}

```
```{r}
head(sample_coef_beta0)
head(sample_coef_beta1)
```


Quick look at the coefficient distributions.
```{r}
par(mfrow=c(1,2))
hist(sample_coef_beta0)
hist(sample_coef_beta1)
```


## SE and CI of Bootstrapped samples and Comparison

Estimate the standard error for each of your β coefficients as the standard deviation of the sampling distribution from your bootstrap and determine the 95% CI for each of your β coefficients based on the appropriate quantiles from your sampling distribution.

How does the former compare to the SE estimated from your entire dataset using the formula for standard error implemented in lm()?

How does the latter compare to the 95% CI estimated from your entire dataset?

### Standard Errors

SEs from the bootstrap.
```{r}
sd(sample_coef_beta0)/sqrt(length((sample_coef_beta0))) # standard error of the intercepts
sd(sample_coef_beta1)/sqrt(length((sample_coef_beta1))) # standard error of the slopes
```
SEs calculated from the entire dataset.
```{r}
model_summary$coefficients[,2]

```

The SEs from the entire dataset differ from the SEs from the bootstrap by a magnitude of 10, so I am concerned that I did something wrong.

### Confidence Intervals

CIs from the bootstrap.
```{r}
quantile(sample_coef_beta0, c(0.025, 0.975)) #95% confidence interval of the intercepts
quantile(sample_coef_beta1, c(0.025, 0.975)) #95% confidence interval of the slopes
```

CIs calculated from the entire dataset
```{r}
confint(model, '(Intercept)', level=0.95)
confint(model, 'log(data$Body_mass_female_mean)', level=0.95)
```

The CIs calculated both ways are pretty similar. The CI of the intercepts are a bit tighter when calculated from the entire dataset than from the bootstrap. Both the upper and lower CI of the slope are greater from the bootstrap than from entire data set. The slope CI from the bootstrap is also a little tighter than the CI from the entire data.